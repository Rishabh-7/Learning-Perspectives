ensemble ,multiple machines ,committee makers ,resultant decision ,overall accuracy ,individual committee member ,class labels ,rankings ,clusterings etc ,posterior probabilities ,ensemble learning ,thea ,real world situations ,machine learning model ,model selection— ,cross validation ,final ,data sample ,data quantity— ,— > ,bulky data ,— > ,different bootstrap ,different classifiers ,bootstrap sample ,random sample ,data drain ,divide ,conquer— ,decision boundary ,certain problems ,classification system ,divide ,classifier learns ,simpler partitions ,data ,suitable combination ,different sources ,data fusion ,confidence ,high confidence decision ,ensemble learning algorithms— ,bagging/bootstrap ,— > ,— > diversity ,boosting ,— > ,creates replicas ,info train data ,consecutive classifiers ,weak classifiers — ,classifier c1 ,random subset ,info subset ,training data ,c2 disagree ,boosting ,binary class problems ,ada boost ,— > instances ,subset dataset ,sample distribution ,— > ,classifiers training errors ,weights majority ,random forests— ,ensemble ,decision tress ,— > ,multi class classification ,— > ,decorate ,diverse ensemble creation ,artificial training examples ,based ,artificial e.g ,— > ,diverse ensembles ,combining ensemble members— ,___________________________________ 1- > majority ,2- > ,3- > borda ,